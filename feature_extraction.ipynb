{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671660f7-2c7e-4552-9af5-5a9db561afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RNA sequence feature extraction using DNABERT-6\n",
    "# ============================================================\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --------------------\n",
    "# Config (edit these paths to your data)\n",
    "# --------------------\n",
    "CIRC_SEQ = \"data/circRNA_sequence.csv\"     # [id, sequence] or just [sequence]\n",
    "MIR_SEQ  = \"data/miRNA_sequence.csv\"       # [id, sequence] or just [sequence]\n",
    "OUT_CIRC = \"data/circRNA_Extractedfeatures.csv\"\n",
    "OUT_MIR  = \"data/miRNA_Extractedfeatures.csv\"\n",
    "\n",
    "MODEL_ID = \"zhihan1996/DNA_bert_6\"\n",
    "K = 6   # k-mer size\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --------------------\n",
    "# DNABERT model\n",
    "# --------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model     = AutoModel.from_pretrained(MODEL_ID).to(device).eval()\n",
    "\n",
    "# --------------------\n",
    "# Helpers\n",
    "# --------------------\n",
    "DNA_RE = re.compile(r\"[^ACGT]\")\n",
    "\n",
    "def clean_dna(seq: str) -> str:\n",
    "    \"\"\"Uppercase, replace Uâ†’T, drop non-ACGT as N.\"\"\"\n",
    "    return DNA_RE.sub(\"N\", str(seq).upper().replace(\"U\", \"T\"))\n",
    "\n",
    "def kmers(seq: str, k=6):\n",
    "    s = clean_dna(seq)\n",
    "    if len(s) < k: return []\n",
    "    return [s[i:i+k] for i in range(len(s)-k+1) if \"N\" not in s[i:i+k]]\n",
    "\n",
    "@torch.no_grad()\n",
    "def dnabert_embed_texts(texts, batch_size=16):\n",
    "    \"\"\"Embed list of k-mer sentences into mean-pooled DNABERT embeddings.\"\"\"\n",
    "    feats = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        toks = tokenizer(\n",
    "            texts[i:i+batch_size],\n",
    "            padding=True, truncation=True, max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        toks = {k:v.to(device) for k,v in toks.items()}\n",
    "        hidden = model(**toks).last_hidden_state       # [B, T, H]\n",
    "        attn   = toks[\"attention_mask\"].unsqueeze(-1)  # [B, T, 1]\n",
    "        pooled = (hidden * attn).sum(1) / attn.sum(1).clamp(min=1)\n",
    "        feats.append(pooled.cpu().numpy())\n",
    "    return np.vstack(feats)\n",
    "\n",
    "def embed_sequences(path: str, outfile: str, label: str):\n",
    "    print(f\"[INFO] Reading {label} sequences from {path}\")\n",
    "    df = pd.read_csv(path, header=None)  # assumes 1 column (sequence) or 2 (id, sequence)\n",
    "    \n",
    "    if df.shape[1] == 1:   # no IDs\n",
    "        seqs = df.iloc[:,0].astype(str).tolist()\n",
    "        ids = [f\"{label}_{i+1}\" for i in range(len(seqs))]\n",
    "    else:                  # first col = ID, second col = sequence\n",
    "        ids = df.iloc[:,0].astype(str).tolist()\n",
    "        seqs = df.iloc[:,1].astype(str).tolist()\n",
    "\n",
    "    print(f\"[INFO] Processing {len(seqs)} {label} sequences...\")\n",
    "    texts, keep_ids = [], []\n",
    "    for idx, s in zip(ids, seqs):\n",
    "        km = kmers(s, K)\n",
    "        if km:\n",
    "            texts.append(\" \".join(km))\n",
    "            keep_ids.append(idx)\n",
    "\n",
    "    print(f\"[INFO] Embedding {len(texts)} {label} sequences with DNABERT...\")\n",
    "    feats = dnabert_embed_texts(texts, batch_size=16)\n",
    "\n",
    "    out_df = pd.DataFrame(feats, index=keep_ids)\n",
    "    out_df.index.name = \"ID\"\n",
    "    out_df.to_csv(outfile)\n",
    "    print(f\"[INFO] Saved {outfile}  shape={out_df.shape}\")\n",
    "\n",
    "# --------------------\n",
    "# Run for circRNA & miRNA\n",
    "# --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    embed_sequences(CIRC_SEQ, OUT_CIRC, \"circRNA\")\n",
    "    embed_sequences(MIR_SEQ,  OUT_MIR,  \"miRNA\")\n",
    "    print(\"[DONE] Feature extraction complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
